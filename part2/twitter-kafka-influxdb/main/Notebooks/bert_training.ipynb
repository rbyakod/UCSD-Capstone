{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d02034c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import sys\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "import random\n",
    "import torch.nn.utils.prune\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19f02e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "\n",
    "    tweet2 = re.sub(r'^RT[\\s]+','', tweet)\n",
    "   \n",
    "    #remove hyperlinks\n",
    "    tweet2 = re.sub(r'https?://[^\\s\\n\\r]+', '', tweet2)\n",
    "    \n",
    "    #remove hashtag by removing the hast #sign from the word\n",
    "    tweet2 = re.sub(r'#','',tweet2)\n",
    "    \n",
    "    \n",
    "    # remove stock market tickers like $GE\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    \n",
    "    #convert into lower case\n",
    "    tweets_clean = tweet.lower()\n",
    "\n",
    "    return tweets_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3c0307",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"https://rbyakod-twitter-analysis.s3.amazonaws.com/data/processed/sentiment_label_data_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec35773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning the tweets \n",
    "data[\"tweets\"] = data[\"text\"].map(lambda x : process_tweet(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4af982",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"tweets\"].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014c6ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset into training and test datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.index.values, data.sentiment.values, test_size = 0.333, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d0ddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"data_type\"] = ['not_set']*data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabe698b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[X_train, 'data_type'] = 'train'\n",
    "data.loc[X_test, 'data_type'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5fe079",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a05855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the data\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74be121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    data[data.data_type=='train'].text.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    "                            \n",
    ")\n",
    "\n",
    "encoded_data_test = tokenizer.batch_encode_plus(\n",
    "    data[data.data_type=='test'].text.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    "                            \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e070a77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_array = data[\"sentiment\"].unique()\n",
    "label_dict = dict(enumerate(label_array.flatten(), 1))\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1eeb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(data[data.data_type=='train'].sentiment.values)\n",
    "\n",
    "# test dataset\n",
    "input_ids_test = encoded_data_test['input_ids']\n",
    "attention_masks_test = encoded_data_test['attention_mask']\n",
    "labels_test = torch.tensor(data[data.data_type=='test'].sentiment.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e70ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing datasets into train and test\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_test = TensorDataset(input_ids_test,attention_masks_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c745ae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up BERT pretrained model\n",
    "from transformers import BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91f2220",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased', \n",
    "    num_labels = len(label_dict),\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28efb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5414d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "   dataset_train, \n",
    "   sampler=RandomSampler(dataset_train),\n",
    "   batch_size=batch_size)\n",
    "\n",
    "dataloader_test = DataLoader(\n",
    "   dataset_test, \n",
    "   sampler=RandomSampler(dataset_test),\n",
    "   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80ff47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4951731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting hyper parameters\n",
    "optimizer = torch.optim.AdamW(\n",
    " model.parameters(),\n",
    "    lr=1e-5,\n",
    "    eps=1e-8   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ff2390",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    " optimizer, num_warmup_steps=0, num_training_steps=len(dataloader_train)*epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58abca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb38e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bab0868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    lables_flat = labels.flatten()\n",
    "    \n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = pred_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cecefd",
   "metadata": {},
   "source": [
    "## Creating our Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3851e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a21fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5440e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader_test):\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_test:\n",
    "        \n",
    "        inputs = {'input_ids': batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels': batch[2]\n",
    "                 }\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "            loss = outputs[0]\n",
    "            logits = outputs[1]\n",
    "            loss_val_total += loss.item()\n",
    "            \n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = inputs['labels'].cpu().numpy()\n",
    "            predictions.append(logits)\n",
    "            true_vals.append(label_ids)\n",
    "        \n",
    "        loss_val_avg = loss_val_total/len(dataloader_test)\n",
    "        \n",
    "        predictions = np.concatenate(predictions, axis=0)\n",
    "        true_vals = np.concatenate(true_vals, axis=0)\n",
    "        \n",
    "        return loss_val_avg, predictions, true_vals\n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36be5c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    model.train()\n",
    "    loss_train_total = 0\n",
    "    progress_bar = tqdm(dataloader_train,\n",
    "                        desc='epoch {:1d}'.format(epoch),\n",
    "                        leave=False,\n",
    "                        disable=False)\n",
    "    for batch in progress_bar:\n",
    "        \n",
    "        model.zero_grad()\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {\n",
    "            'input_ids' : batch[0],\n",
    "            'attention_mask' : batch[1],\n",
    "            'labels' : batch[2]\n",
    "        }\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss= outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "        \n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "                                   \n",
    "    print('training_loss : ',(loss.item()/len(batch)))    \n",
    "    torch.save(model.state_dict(), f'BERT_ft_epoch{epoch}.model')    \n",
    "    tqdm.write('\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)\n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "\n",
    "    \n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_test)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (weighted): {val_f1}')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1a052f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
